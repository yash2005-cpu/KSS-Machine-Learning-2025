{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yash2005-cpu/KSS-Machine-Learning-2025/blob/main/5_DeepLearning_ClassificationTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "-Z0nY1bPcy7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Neural Networks\n",
        "\n",
        "- Traditional Machine Learning algorithms were trained on extracted features.\n",
        "  - Scaled well for problems involving structured data (tabular)\n",
        "  - Did not scale well for problems involving unstructured data (images, videos, audio, speech, etc)\n",
        "\n",
        "Additional References:\n",
        "1. CMU: 11-785 Introduction to Deep Learning (Spring 2025)\n",
        "https://youtu.be/NXYrIEP1LRs"
      ],
      "metadata": {
        "id": "TWrWzdM7dD6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "MkPubzxfvkSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters (User Configurable)\n",
        "learning_rate = 0.001  #@param {type:\"number\"}\n",
        "random_seed = 42  #@param {type:\"integer\"}\n",
        "num_epochs = 8 #@param {type:\"integer\"}\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ],
      "metadata": {
        "id": "fk6gFDOYvo_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "id": "epiGCioGvz-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading and preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "metadata": {
        "id": "k9O1SvBQv-b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "print(f\"Train dataset classes: {train_loader.dataset.classes}\")\n",
        "print(f\"Test dataset classes: {test_loader.dataset.classes}\")"
      ],
      "metadata": {
        "id": "OQw8QnFqwDC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YpUZqTNIwgwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "L2hkNF8tw6Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    # print(f\"Epoch = {epoch}\")\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # print(f\"batch number = {batch_idx}\")\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "CKeLHbmfw8iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop and generating evaluation metrics\n",
        "def test():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = model(data)\n",
        "          _, predicted = torch.max(output.data, 1)\n",
        "          total += target.size(0)\n",
        "          correct += (predicted == target).sum().item()\n",
        "          all_preds.extend(predicted.cpu().numpy())\n",
        "          all_targets.extend(target.cpu().numpy())\n",
        "    return correct / total, all_preds, all_targets"
      ],
      "metadata": {
        "id": "058m--EZw-x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test accuracy before training\n",
        "accuracy, predictions, targets = test()\n",
        "print(f'Before training: Test Accuracy {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "_Id_B7XFxWj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(epoch)\n",
        "    accuracy, predictions, targets = test()\n",
        "    print(f'Epoch {epoch}: Test Accuracy {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "iHUwBuzExBk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional Evaluations (after training)\n",
        "print(classification_report(targets, predictions))\n",
        "\n",
        "cm = confusion_matrix(targets, predictions)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9W3NhCA0xFfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXERCISE:\n",
        "1. Modify the code to plot the training accuracy and loss over the training epochs\n",
        "\n",
        "2. Modify the code to plot the test accuracy over the training epochs\n",
        "\n",
        "3. Plot example inferences and show actual and predicted values"
      ],
      "metadata": {
        "id": "hU4zHIkux7Fx"
      }
    }
  ]
}